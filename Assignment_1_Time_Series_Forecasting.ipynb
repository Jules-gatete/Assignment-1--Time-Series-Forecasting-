{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO55H2hxgct3mMs53SElO9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jules-gatete/Assignment-1--Time-Series-Forecasting-/blob/main/Assignment_1_Time_Series_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "\n",
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import optuna\n",
        "import os"
      ],
      "metadata": {
        "id": "fxB1yo_DFecI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Enable mixed precision training\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "g2QSN9f4Fb7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Data Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "kmFAxh1u7epl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Convert datetime\n",
        "train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n",
        "test_df['datetime'] = pd.to_datetime(test_df['datetime'])\n",
        "\n",
        "# Handle missing values\n",
        "train_df = train_df.dropna(subset=['pm2.5']).interpolate(method='linear')\n",
        "test_df = test_df.interpolate(method='linear')"
      ],
      "metadata": {
        "id": "aVxxhQ5T74z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiGBqQXa_x5v",
        "outputId": "be37e204-0719-4042-af34-d74d6e9a0601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['No', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'datetime', 'cbwd_NW',\n",
            "       'cbwd_SE', 'cbwd_cv', 'pm2.5'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences with stride\n",
        "def create_sequences(data, target, seq_length, stride=1):\n",
        "    X, y = [], []\n",
        "    for i in range(0, len(data) - seq_length, stride):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(target[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "3-qDHSUS8EYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: Extract temporal features from datetime\n",
        "train_df['hour'] = train_df['datetime'].dt.hour\n",
        "train_df['day'] = train_df['datetime'].dt.day\n",
        "train_df['month'] = train_df['datetime'].dt.month\n",
        "train_df['dayofweek'] = train_df['datetime'].dt.dayofweek\n",
        "\n",
        "test_df['hour'] = test_df['datetime'].dt.hour\n",
        "test_df['day'] = test_df['datetime'].dt.day\n",
        "test_df['month'] = test_df['datetime'].dt.month\n",
        "test_df['dayofweek'] = test_df['datetime'].dt.dayofweek\n",
        "\n",
        "# Define feature columns (adjust based on your dataset)\n",
        "feature_columns = ['DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'cbwd_NW', 'cbwd_SE', 'cbwd_cv',\n",
        "                   'hour', 'day', 'month', 'dayofweek']\n",
        "\n",
        "# Scale features and target\n",
        "scaler_features = MinMaxScaler()\n",
        "scaler_pm25 = MinMaxScaler()\n",
        "\n",
        "# Fit and transform features\n",
        "train_df[feature_columns] = scaler_features.fit_transform(train_df[feature_columns])\n",
        "test_df[feature_columns] = scaler_features.transform(test_df[feature_columns])\n",
        "\n",
        "# Fit and transform target (pm2.5)\n",
        "train_df['pm2.5_scaled'] = scaler_pm25.fit_transform(train_df[['pm2.5']])"
      ],
      "metadata": {
        "id": "cMaylvhaAX5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Model Definition**\n"
      ],
      "metadata": {
        "id": "Y89r__sV8WJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(seq_length, n_features, units, layers, dropout, learning_rate):\n",
        "    model = Sequential()\n",
        "    if layers == 1:\n",
        "        model.add(LSTM(units, activation='relu', input_shape=(seq_length, n_features)))\n",
        "        model.add(Dropout(dropout))\n",
        "    else:\n",
        "        model.add(LSTM(units, activation='relu', input_shape=(seq_length, n_features), return_sequences=True))\n",
        "        model.add(Dropout(dropout))\n",
        "        for _ in range(layers - 2):\n",
        "            model.add(LSTM(units // 2, activation='relu', return_sequences=True))\n",
        "            model.add(Dropout(dropout))\n",
        "        model.add(LSTM(units // 2, activation='relu'))\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, dtype='float32'))  # Ensure output is float32 for mixed precision\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fVRvsGGe8dve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Hyperparameter Optimization with Optuna**\n"
      ],
      "metadata": {
        "id": "kgpGKmDo8j9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'seq_length': trial.suggest_int('seq_length', 12, 48, step=12),\n",
        "        'units': trial.suggest_int('units', 32, 128, step=32),\n",
        "        'layers': trial.suggest_int('layers', 1, 3),\n",
        "        'dropout': trial.suggest_float('dropout', 0.1, 0.4, step=0.1),\n",
        "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
        "        'stride': trial.suggest_int('stride', 1, 3)\n",
        "    }\n",
        "\n",
        "    X_train, y_train = create_sequences(\n",
        "        train_df[feature_columns].values,\n",
        "        train_df['pm2.5_scaled'].values,\n",
        "        params['seq_length'],\n",
        "        params['stride']\n",
        "    )\n",
        "\n",
        "    model = build_model(\n",
        "        params['seq_length'],\n",
        "        len(feature_columns),\n",
        "        params['units'],\n",
        "        params['layers'],\n",
        "        params['dropout'],\n",
        "        params['lr']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=30,  # Reduced epochs for faster training\n",
        "        batch_size=params['batch_size'],\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_predictions = model.predict(X_train[-int(0.2 * len(X_train)):], verbose=0)\n",
        "    val_true = y_train[-int(0.2 * len(X_train)):]\n",
        "    val_predictions = scaler_pm25.inverse_transform(val_predictions)\n",
        "    val_true = scaler_pm25.inverse_transform(val_true.reshape(-1, 1))\n",
        "    rmse = np.sqrt(np.mean((val_true - val_predictions) ** 2))\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "nTPFzl2yETOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "best_params = study.best_params\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best RMSE: {study.best_value:.2f}\")"
      ],
      "metadata": {
        "id": "Mff1lQ9zEVoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Iterative Prediction for Test Set**\n"
      ],
      "metadata": {
        "id": "fQxE5Jwx9T5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_predict(model, train_data, test_data, seq_length, feature_columns, scaler_pm25):\n",
        "    predictions = []\n",
        "    last_sequence = train_data[feature_columns].values[-seq_length:].copy()\n",
        "    last_pm25 = train_data['pm2.5_scaled'].values[-seq_length:].reshape(-1, 1)\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        # Prepare input sequence\n",
        "        X = np.array([last_sequence])\n",
        "        pred_scaled = model.predict(X, verbose=0)\n",
        "        pred = scaler_pm25.inverse_transform(pred_scaled)[0, 0]\n",
        "        predictions.append(pred)\n",
        "\n",
        "        # Update sequence with test data and predicted PM2.5\n",
        "        next_row = test_data[feature_columns].iloc[i].values\n",
        "        last_sequence = np.vstack([last_sequence[1:], next_row])\n",
        "        last_pm25 = np.vstack([last_pm25[1:], pred_scaled])\n",
        "\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "itLi6RFl9nSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with best parameters\n",
        "X_train, y_train = create_sequences(\n",
        "    train_df[feature_columns].values,\n",
        "    train_df['pm2.5_scaled'].values,\n",
        "    best_params['seq_length'],\n",
        "    best_params['stride']\n",
        ")\n",
        "\n",
        "final_model = build_model(\n",
        "    best_params['seq_length'],\n",
        "    len(feature_columns),\n",
        "    best_params['units'],\n",
        "    best_params['layers'],\n",
        "    best_params['dropout'],\n",
        "    best_params['lr']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=30,\n",
        "    batch_size=best_params['batch_size'],\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D62hSH079qwd",
        "outputId": "7d9d2eb7-2fd3-4a42-a391-c7fe3a806935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7afeb63bd1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predictions = iterative_predict(final_model, train_df, test_df, best_params['seq_length'], feature_columns, scaler_pm25)\n",
        "\n",
        "# Create submission\n",
        "final_submission = pd.DataFrame({\n",
        "    'row ID': test_df['datetime'].dt.strftime('%Y-%m-%d %-H:%M:%S'),\n",
        "    'pm2.5': predictions\n",
        "})\n",
        "final_submission.to_csv('/content/submission3.csv', index=False)\n",
        "print(\"Final submission saved as 'submission.csv'\")"
      ],
      "metadata": {
        "id": "swVfukAwEJjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation predictions for best model\n",
        "val_predictions = final_model.predict(X_train[-100:], verbose=0)\n",
        "val_true = y_train[-100:]\n",
        "val_predictions = scaler_pm25.inverse_transform(val_predictions)\n",
        "val_true = scaler_pm25.inverse_transform(val_true.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "zedAIPUcFpN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**"
      ],
      "metadata": {
        "id": "kiqTBxTaA6x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a line chart for actual vs predicted PM2.5\n",
        "chart_data = {\n",
        "    \"type\": \"line\",\n",
        "    \"data\": {\n",
        "        \"labels\": list(range(100)),\n",
        "        \"datasets\": [\n",
        "            {\n",
        "                \"label\": \"Actual PM2.5\",\n",
        "                \"data\": val_true.flatten().tolist(),\n",
        "                \"borderColor\": \"#1f77b4\",\n",
        "                \"fill\": False\n",
        "            },\n",
        "            {\n",
        "                \"label\": \"Predicted PM2.5\",\n",
        "                \"data\": val_predictions.flatten().tolist(),\n",
        "                \"borderColor\": \"#ff7f0e\",\n",
        "                \"fill\": False\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"options\": {\n",
        "        \"title\": {\n",
        "            \"display\": True,\n",
        "            \"text\": \"Best Model: Actual vs Predicted PM2.5\"\n",
        "        },\n",
        "        \"scales\": {\n",
        "            \"x\": {\n",
        "                \"title\": {\n",
        "                    \"display\": True,\n",
        "                    \"text\": \"Sample\"\n",
        "                }\n",
        "            },\n",
        "            \"y\": {\n",
        "                \"title\": {\n",
        "                    \"display\": True,\n",
        "                    \"text\": \"PM2.5 (µg/m³)\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "DrF7QrKCEO1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}